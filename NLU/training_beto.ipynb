{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52b47eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    EarlyStoppingCallback,\n",
    "    pipeline\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "from seqeval.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86e95d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA GeForce RTX 3060 Ti\n",
      "Memory: 8.6 GB\n"
     ]
    }
   ],
   "source": [
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "985fa71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path configuration\n",
    "JSONL_DIR = Path(r\"data\\jsonls\")\n",
    "LABELS_TXT = r\"data\\labels.txt\"\n",
    "\n",
    "# Model configuration\n",
    "MODEL_CHECKPOINT = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
    "OUTPUT_DIR = r\"models\\beto-ner\"\n",
    "\n",
    "# Data split ratios\n",
    "VAL_SPLIT  = 0.10  \n",
    "TEST_SPLIT = 0.15       \n",
    "\n",
    "# Tokenization parameters\n",
    "MAX_LENGTH = 512\n",
    "DOC_STRIDE = 128\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2242691b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Companies found: 6\n",
      "Total records: 166\n",
      "\n",
      "TOTAL DOCS: Train: 128 | Val: 16 | Test: 22\n",
      "TOTAL RECS: Train: 128 | Val: 16 | Test: 22\n",
      "Train/val overlap: 0\n",
      "Train/test overlap: 0\n",
      "Val/test overlap: 0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from datasets import Dataset, DatasetDict\n",
    "import shutil\n",
    "\n",
    "# Load labels and create BIO tags\n",
    "with open(LABELS_TXT, \"r\", encoding=\"utf-8\") as f:\n",
    "    base_labels = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "base_labels = [l for l in base_labels if l != \"O\"]\n",
    "\n",
    "bio_labels = [\"O\"]\n",
    "for lab in base_labels:\n",
    "    bio_labels.append(f\"B-{lab}\")\n",
    "    bio_labels.append(f\"I-{lab}\")\n",
    "\n",
    "label2id = {l: i for i, l in enumerate(bio_labels)}\n",
    "id2label = {i: l for l, i in label2id.items()}\n",
    "\n",
    "# Read JSONL files organized by company (subfolders)\n",
    "records = []\n",
    "by_company_by_doc = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "company_dirs = [p for p in sorted(JSONL_DIR.iterdir()) if p.is_dir()]\n",
    "\n",
    "for company_dir in company_dirs:\n",
    "    company = company_dir.name\n",
    "    for jsonl_file in sorted(company_dir.glob(\"*.jsonl\")):\n",
    "        with open(jsonl_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                r = json.loads(line)\n",
    "                r[\"entities\"] = r.get(\"entities\") or []\n",
    "                r[\"doc_id\"] = r.get(\"doc_id\") or jsonl_file.stem\n",
    "                r[\"company\"] = r.get(\"company\") or company\n",
    "\n",
    "                records.append(r)\n",
    "                by_company_by_doc[company][r[\"doc_id\"]].append(r)\n",
    "\n",
    "print(f\"Companies found: {len(company_dirs)}\")\n",
    "print(\"Total records:\", len(records))\n",
    "\n",
    "# Document-level split by company (prevents data leakage)\n",
    "train_recs, val_recs, test_recs = [], [], []\n",
    "train_docs, val_docs, test_docs = set(), set(), set()\n",
    "\n",
    "rng = random.Random(SEED)\n",
    "\n",
    "for company, by_doc in by_company_by_doc.items():\n",
    "    doc_ids = list(by_doc.keys())\n",
    "    rng.shuffle(doc_ids)\n",
    "\n",
    "    n = len(doc_ids)\n",
    "    n_val  = int(n * VAL_SPLIT)\n",
    "    n_test = int(n * TEST_SPLIT)\n",
    "\n",
    "    # Ensure minimum samples if enough documents\n",
    "    if n >= 3:\n",
    "        n_val  = max(n_val, 1)\n",
    "        n_test = max(n_test, 1)\n",
    "\n",
    "    # Ensure at least 1 document in train\n",
    "    if n_val + n_test > n - 1:\n",
    "        overflow = (n_val + n_test) - (n - 1)\n",
    "        cut_test = min(overflow, n_test)\n",
    "        n_test -= cut_test\n",
    "        overflow -= cut_test\n",
    "        if overflow > 0:\n",
    "            n_val = max(0, n_val - overflow)\n",
    "\n",
    "    val_doc_ids   = set(doc_ids[:n_val])\n",
    "    test_doc_ids  = set(doc_ids[n_val:n_val + n_test])\n",
    "    train_doc_ids = set(doc_ids[n_val + n_test:])\n",
    "\n",
    "    val_docs   |= val_doc_ids\n",
    "    test_docs  |= test_doc_ids\n",
    "    train_docs |= train_doc_ids\n",
    "\n",
    "    val_recs   += [r for d in val_doc_ids   for r in by_doc[d]]\n",
    "    test_recs  += [r for d in test_doc_ids  for r in by_doc[d]]\n",
    "    train_recs += [r for d in train_doc_ids for r in by_doc[d]]\n",
    "\n",
    "print(f\"\\nTOTAL DOCS: Train: {len(train_docs)} | Val: {len(val_docs)} | Test: {len(test_docs)}\")\n",
    "print(f\"TOTAL RECS: Train: {len(train_recs)} | Val: {len(val_recs)} | Test: {len(test_recs)}\")\n",
    "print(\"Train/val overlap:\", len(train_docs & val_docs))\n",
    "print(\"Train/test overlap:\", len(train_docs & test_docs))\n",
    "print(\"Val/test overlap:\", len(val_docs & test_docs))\n",
    "\n",
    "# Build HuggingFace DatasetDict\n",
    "raw_datasets = DatasetDict({\n",
    "    \"train\":      Dataset.from_list(train_recs),\n",
    "    \"validation\": Dataset.from_list(val_recs),\n",
    "    \"test\":       Dataset.from_list(test_recs),\n",
    "})\n",
    "\n",
    "# Copy test documents for later inference\n",
    "rawtxts_dir = Path(\"../data/rawtexts\")\n",
    "dst_dir = Path(\"data/testinvoicesjson\")\n",
    "dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "test_doc_ids = {r[\"doc_id\"] for r in test_recs}\n",
    "moved = 0\n",
    "\n",
    "for txt_file in rawtxts_dir.rglob(\"*.txt\"):\n",
    "    if txt_file.stem in test_doc_ids:\n",
    "        shutil.copy2(txt_file, dst_dir / txt_file.name)\n",
    "        moved += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6908f63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer: dccuchile/bert-base-spanish-wwm-cased (vocab: 31,002)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e6ba3ec33c49ecab2a542d2f18f0cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/128 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63474786bb5145089d709ea92cadd6e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e24cdf2500449ebf5b14367197d7f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels', 'overflow_to_sample_mapping'],\n",
       "        num_rows: 882\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels', 'overflow_to_sample_mapping'],\n",
       "        num_rows: 88\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels', 'overflow_to_sample_mapping'],\n",
       "        num_rows: 130\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_CHECKPOINT,\n",
    "    use_fast=True,\n",
    ")\n",
    "print(f\"Tokenizer: {MODEL_CHECKPOINT} (vocab: {tokenizer.vocab_size:,})\")\n",
    "\n",
    "def char_spans_to_marks(text, entities):\n",
    "    \"\"\"\n",
    "    Map character positions to entity indices.\n",
    "    Handles overlaps by prioritizing longer spans.\n",
    "    \"\"\"\n",
    "    marks = [None] * len(text)\n",
    "    sorted_ents = sorted(entities, key=lambda e: (-(e[\"end\"]-e[\"start\"]), e[\"start\"]))\n",
    "    for idx, ent in enumerate(sorted_ents):\n",
    "        s, e = ent[\"start\"], ent[\"end\"]\n",
    "        for i in range(max(0, s), min(len(text), e)):\n",
    "            if marks[i] is None:\n",
    "                marks[i] = idx\n",
    "    return marks, sorted_ents\n",
    "\n",
    "def tokenize_and_align_v3(batch):\n",
    "    \"\"\"\n",
    "    Tokenize texts and align character-level entity spans to subword tokens.\n",
    "    Uses BIO tagging scheme with sliding windows for long documents.\n",
    "    \"\"\"\n",
    "    texts = batch[\"text\"]\n",
    "    ents_list = batch.get(\"entities\", [[]] * len(texts))\n",
    "\n",
    "    out = {\n",
    "        \"input_ids\": [],\n",
    "        \"attention_mask\": [],\n",
    "        \"labels\": [],\n",
    "        \"overflow_to_sample_mapping\": [],\n",
    "    }\n",
    "\n",
    "    for text, entities in zip(texts, ents_list):\n",
    "        marks, sorted_ents = char_spans_to_marks(text, entities)\n",
    "\n",
    "        enc = tokenizer(\n",
    "            text,\n",
    "            return_offsets_mapping=True,\n",
    "            max_length=MAX_LENGTH,\n",
    "            truncation=True,\n",
    "            stride=DOC_STRIDE,\n",
    "            return_overflowing_tokens=True,\n",
    "        )\n",
    "\n",
    "        otm = enc.get(\"overflow_to_sample_mapping\", [0] * len(enc[\"input_ids\"]))\n",
    "\n",
    "        for i in range(len(enc[\"input_ids\"])):\n",
    "            offsets = enc[\"offset_mapping\"][i]\n",
    "            lbl_ids = [-100] * len(offsets)\n",
    "            prev_ent_idx = None\n",
    "\n",
    "            for j, (start, end) in enumerate(offsets):\n",
    "                if start == end:\n",
    "                    continue\n",
    "\n",
    "                ent_idx = None\n",
    "                for k in range(start, end):\n",
    "                    if 0 <= k < len(marks) and marks[k] is not None:\n",
    "                        ent_idx = marks[k]\n",
    "                        break\n",
    "\n",
    "                if ent_idx is None:\n",
    "                    lbl_ids[j] = label2id[\"O\"]\n",
    "                else:\n",
    "                    lab = sorted_ents[ent_idx][\"label\"]  # ie: \"EAN\"\n",
    "                    tag = (\"B-\" if prev_ent_idx != ent_idx else \"I-\") + lab  # \"B-EAN\"/\"I-EAN\"\n",
    "\n",
    "                    lbl_ids[j] = label2id[tag]\n",
    "\n",
    "                prev_ent_idx = ent_idx\n",
    "\n",
    "            out[\"input_ids\"].append(enc[\"input_ids\"][i])\n",
    "            out[\"attention_mask\"].append(enc[\"attention_mask\"][i])\n",
    "            out[\"labels\"].append(lbl_ids)\n",
    "            out[\"overflow_to_sample_mapping\"].append(otm[i])\n",
    "\n",
    "    return out\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_and_align_v3,\n",
    "    batched=True,\n",
    "    batch_size=10,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")\n",
    "\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00861f04-c0b6-4b2a-bae7-b400e8c94878",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollatorForTokenClassification(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "def compute_metrics(p):\n",
    "    \"\"\"\n",
    "    Compute entity-level metrics using seqeval.\n",
    "    Returns micro/macro averaged precision, recall, F1, and per-entity metrics.\n",
    "    \"\"\"\n",
    "    preds = np.argmax(p.predictions, axis=-1)\n",
    "    labels = p.label_ids\n",
    "\n",
    "    # Filter out special tokens (-100)\n",
    "    true_predictions, true_labels = [], []\n",
    "    for pred, lab in zip(preds, labels):\n",
    "        cur_pred, cur_lab = [], []\n",
    "        for p_i, l_i in zip(pred, lab):\n",
    "            if l_i == -100:\n",
    "                continue\n",
    "            cur_pred.append(id2label[int(p_i)])\n",
    "            cur_lab.append(id2label[int(l_i)])\n",
    "        true_predictions.append(cur_pred)\n",
    "        true_labels.append(cur_lab)\n",
    "\n",
    "    # Global metrics\n",
    "    metrics = {\n",
    "        \"precision\": precision_score(true_labels, true_predictions),\n",
    "        \"recall\":    recall_score(true_labels, true_predictions),\n",
    "        \"f1\":        f1_score(true_labels, true_predictions),\n",
    "        \"precision_macro\": precision_score(true_labels, true_predictions, average=\"macro\"),\n",
    "        \"recall_macro\":    recall_score(true_labels, true_predictions, average=\"macro\"),\n",
    "        \"f1_macro\":        f1_score(true_labels, true_predictions, average=\"macro\"),\n",
    "        \"accuracy\":  accuracy_score(true_labels, true_predictions),\n",
    "    }\n",
    "\n",
    "    # Per-entity metrics\n",
    "    rep = classification_report(true_labels, true_predictions, output_dict=True, zero_division=0)\n",
    "    \n",
    "    # Print detailed report only for final evaluation\n",
    "    if len(true_labels) > 100:  # Heuristic: val/test sets are larger\n",
    "        print(\"\\n\" + classification_report(true_labels, true_predictions, zero_division=0))\n",
    "\n",
    "    for ent, vals in rep.items():\n",
    "        if ent in {\"micro avg\", \"macro avg\", \"weighted avg\"}:\n",
    "            continue\n",
    "        if isinstance(vals, dict) and \"f1-score\" in vals:\n",
    "            metrics[f\"precision_{ent}\"] = float(vals[\"precision\"])\n",
    "            metrics[f\"recall_{ent}\"]    = float(vals[\"recall\"])\n",
    "            metrics[f\"f1_{ent}\"]        = float(vals[\"f1-score\"])\n",
    "            metrics[f\"support_{ent}\"]   = float(vals[\"support\"])\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d20b3d1b-66fe-4997-86bf-c60aeb85d507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model: dccuchile/bert-base-spanish-wwm-cased\n",
      "  Parameters: 109,271,823\n",
      "  Labels: 15\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(label2id)\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    MODEL_CHECKPOINT,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "print(f\"✓ Model: {MODEL_CHECKPOINT}\")\n",
    "print(f\"  Parameters: {model.num_parameters():,}\")\n",
    "print(f\"  Labels: {num_labels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59e59a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:      1.5e-05\n",
      "Epochs:             10\n",
      "Batch size:         16 (effective)\n",
      "Label smoothing:    0.1\n",
      "Device:             GPU (FP16)\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='560' max='560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [560/560 22:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Cantidad</th>\n",
       "      <th>Recall Cantidad</th>\n",
       "      <th>F1 Cantidad</th>\n",
       "      <th>Support Cantidad</th>\n",
       "      <th>Precision Ean</th>\n",
       "      <th>Recall Ean</th>\n",
       "      <th>F1 Ean</th>\n",
       "      <th>Support Ean</th>\n",
       "      <th>Precision Fecha</th>\n",
       "      <th>Recall Fecha</th>\n",
       "      <th>F1 Fecha</th>\n",
       "      <th>Support Fecha</th>\n",
       "      <th>Precision Nombre Producto</th>\n",
       "      <th>Recall Nombre Producto</th>\n",
       "      <th>F1 Nombre Producto</th>\n",
       "      <th>Support Nombre Producto</th>\n",
       "      <th>Precision Numero Factura</th>\n",
       "      <th>Recall Numero Factura</th>\n",
       "      <th>F1 Numero Factura</th>\n",
       "      <th>Support Numero Factura</th>\n",
       "      <th>Precision Precio Coste Unidad</th>\n",
       "      <th>Recall Precio Coste Unidad</th>\n",
       "      <th>F1 Precio Coste Unidad</th>\n",
       "      <th>Support Precio Coste Unidad</th>\n",
       "      <th>Precision Sku</th>\n",
       "      <th>Recall Sku</th>\n",
       "      <th>F1 Sku</th>\n",
       "      <th>Support Sku</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.492000</td>\n",
       "      <td>0.877032</td>\n",
       "      <td>0.172516</td>\n",
       "      <td>0.147382</td>\n",
       "      <td>0.158962</td>\n",
       "      <td>0.206441</td>\n",
       "      <td>0.104544</td>\n",
       "      <td>0.113889</td>\n",
       "      <td>0.884911</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.185547</td>\n",
       "      <td>0.313015</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>0.078846</td>\n",
       "      <td>0.136667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.312925</td>\n",
       "      <td>0.349146</td>\n",
       "      <td>0.330045</td>\n",
       "      <td>527.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.010929</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.005690</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>0.042386</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.048474</td>\n",
       "      <td>477.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.643000</td>\n",
       "      <td>0.620605</td>\n",
       "      <td>0.932872</td>\n",
       "      <td>0.968328</td>\n",
       "      <td>0.950269</td>\n",
       "      <td>0.668480</td>\n",
       "      <td>0.701154</td>\n",
       "      <td>0.684330</td>\n",
       "      <td>0.984129</td>\n",
       "      <td>0.977055</td>\n",
       "      <td>0.998047</td>\n",
       "      <td>0.987440</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>0.960912</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.971993</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.898955</td>\n",
       "      <td>0.979127</td>\n",
       "      <td>0.937330</td>\n",
       "      <td>527.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.921960</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.948646</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>0.920477</td>\n",
       "      <td>0.970650</td>\n",
       "      <td>0.944898</td>\n",
       "      <td>477.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>0.602716</td>\n",
       "      <td>0.944943</td>\n",
       "      <td>0.978463</td>\n",
       "      <td>0.961411</td>\n",
       "      <td>0.744376</td>\n",
       "      <td>0.786081</td>\n",
       "      <td>0.762013</td>\n",
       "      <td>0.989142</td>\n",
       "      <td>0.978927</td>\n",
       "      <td>0.998047</td>\n",
       "      <td>0.988395</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>0.967427</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.978583</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.948624</td>\n",
       "      <td>0.981025</td>\n",
       "      <td>0.964552</td>\n",
       "      <td>527.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.950459</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.972770</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>0.931864</td>\n",
       "      <td>0.974843</td>\n",
       "      <td>0.952869</td>\n",
       "      <td>477.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.574700</td>\n",
       "      <td>0.598787</td>\n",
       "      <td>0.961097</td>\n",
       "      <td>0.991132</td>\n",
       "      <td>0.975884</td>\n",
       "      <td>0.905174</td>\n",
       "      <td>0.932964</td>\n",
       "      <td>0.918781</td>\n",
       "      <td>0.990235</td>\n",
       "      <td>0.982692</td>\n",
       "      <td>0.998047</td>\n",
       "      <td>0.990310</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>0.967427</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.978583</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.964880</td>\n",
       "      <td>0.990512</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>527.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.947080</td>\n",
       "      <td>0.998077</td>\n",
       "      <td>0.971910</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>0.959432</td>\n",
       "      <td>0.991614</td>\n",
       "      <td>0.975258</td>\n",
       "      <td>477.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.568800</td>\n",
       "      <td>0.592341</td>\n",
       "      <td>0.972303</td>\n",
       "      <td>0.993243</td>\n",
       "      <td>0.982661</td>\n",
       "      <td>0.942890</td>\n",
       "      <td>0.943042</td>\n",
       "      <td>0.942627</td>\n",
       "      <td>0.991565</td>\n",
       "      <td>0.982726</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991288</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.972119</td>\n",
       "      <td>0.992410</td>\n",
       "      <td>0.982160</td>\n",
       "      <td>527.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.970093</td>\n",
       "      <td>0.998077</td>\n",
       "      <td>0.983886</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>0.971370</td>\n",
       "      <td>0.995807</td>\n",
       "      <td>0.983437</td>\n",
       "      <td>477.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.568300</td>\n",
       "      <td>0.596590</td>\n",
       "      <td>0.969174</td>\n",
       "      <td>0.995777</td>\n",
       "      <td>0.982295</td>\n",
       "      <td>0.960017</td>\n",
       "      <td>0.970645</td>\n",
       "      <td>0.965046</td>\n",
       "      <td>0.991162</td>\n",
       "      <td>0.982726</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991288</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.996205</td>\n",
       "      <td>0.984067</td>\n",
       "      <td>527.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>0.971370</td>\n",
       "      <td>0.995807</td>\n",
       "      <td>0.983437</td>\n",
       "      <td>477.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.566700</td>\n",
       "      <td>0.595048</td>\n",
       "      <td>0.973999</td>\n",
       "      <td>0.996622</td>\n",
       "      <td>0.985181</td>\n",
       "      <td>0.963211</td>\n",
       "      <td>0.971445</td>\n",
       "      <td>0.967086</td>\n",
       "      <td>0.991803</td>\n",
       "      <td>0.982726</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991288</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>0.970684</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.981878</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.977654</td>\n",
       "      <td>0.996205</td>\n",
       "      <td>0.986842</td>\n",
       "      <td>527.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.961111</td>\n",
       "      <td>0.998077</td>\n",
       "      <td>0.979245</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>0.979466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989627</td>\n",
       "      <td>477.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.564600</td>\n",
       "      <td>0.593994</td>\n",
       "      <td>0.978838</td>\n",
       "      <td>0.996199</td>\n",
       "      <td>0.987442</td>\n",
       "      <td>0.975598</td>\n",
       "      <td>0.979626</td>\n",
       "      <td>0.977408</td>\n",
       "      <td>0.991946</td>\n",
       "      <td>0.982726</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991288</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.975791</td>\n",
       "      <td>0.994307</td>\n",
       "      <td>0.984962</td>\n",
       "      <td>527.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.981096</td>\n",
       "      <td>0.998077</td>\n",
       "      <td>0.989514</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990654</td>\n",
       "      <td>477.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.563100</td>\n",
       "      <td>0.593813</td>\n",
       "      <td>0.976840</td>\n",
       "      <td>0.997466</td>\n",
       "      <td>0.987046</td>\n",
       "      <td>0.965033</td>\n",
       "      <td>0.972192</td>\n",
       "      <td>0.968391</td>\n",
       "      <td>0.992278</td>\n",
       "      <td>0.982726</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991288</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>0.970779</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.983553</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.979516</td>\n",
       "      <td>0.998102</td>\n",
       "      <td>0.988722</td>\n",
       "      <td>527.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.971910</td>\n",
       "      <td>0.998077</td>\n",
       "      <td>0.984820</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>0.979466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989627</td>\n",
       "      <td>477.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.563200</td>\n",
       "      <td>0.594163</td>\n",
       "      <td>0.974412</td>\n",
       "      <td>0.997044</td>\n",
       "      <td>0.985598</td>\n",
       "      <td>0.963466</td>\n",
       "      <td>0.971921</td>\n",
       "      <td>0.967453</td>\n",
       "      <td>0.991946</td>\n",
       "      <td>0.980843</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990329</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>0.970779</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.983553</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.977654</td>\n",
       "      <td>0.996205</td>\n",
       "      <td>0.986842</td>\n",
       "      <td>527.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.964684</td>\n",
       "      <td>0.998077</td>\n",
       "      <td>0.981096</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>0.979466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989627</td>\n",
       "      <td>477.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score: 0.9874\n",
      "Training time: 1325.76s\n",
      "Samples/second: 6.65\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    learning_rate=1.5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.15,\n",
    "    logging_steps=25,\n",
    "    logging_dir=os.path.join(OUTPUT_DIR, \"logs\"),\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    seed=SEED,\n",
    "    data_seed=SEED,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"adamw_torch\",\n",
    "    report_to=\"none\",\n",
    "    label_smoothing_factor=0.1,\n",
    ")\n",
    "\n",
    "print(f\"Learning rate:      {args.learning_rate}\")\n",
    "print(f\"Epochs:             {args.num_train_epochs}\")\n",
    "print(f\"Batch size:         {args.per_device_train_batch_size * args.gradient_accumulation_steps} (effective)\")\n",
    "print(f\"Label smoothing:    {args.label_smoothing_factor}\")\n",
    "print(f\"Device:             {'GPU (FP16)' if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=4)],\n",
    "    data_collator=collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(f\"Best F1 score: {trainer.state.best_metric:.4f}\")\n",
    "print(f\"Training time: {train_result.metrics.get('train_runtime', 0):.2f}s\")\n",
    "print(f\"Samples/second: {train_result.metrics.get('train_samples_per_second', 0):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aac53b66",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1: 0.9874\n"
     ]
    }
   ],
   "source": [
    "# Save trained model\n",
    "# trainer.save_model(OUTPUT_DIR)\n",
    "# tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "\n",
    "# Validation evaluation\n",
    "val_metrics = trainer.evaluate()\n",
    "\n",
    "# Save metrics\n",
    "with open(os.path.join(OUTPUT_DIR, \"val_metrics.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(val_metrics, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# print(f\"\\nModel saved: {OUTPUT_DIR}\")\n",
    "print(f\"Validation F1: {val_metrics.get('eval_f1', 0):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fec3998",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Load inference pipeline\n",
    "pipe = pipeline(\n",
    "    \"token-classification\",\n",
    "    model=OUTPUT_DIR,\n",
    "    tokenizer=OUTPUT_DIR,\n",
    "    aggregation_strategy=\"simple\",\n",
    "    device=0 if torch.cuda.is_available() else -1,\n",
    ")\n",
    "\n",
    "def ner_long_text(pipe, text, chunk_chars=1400, overlap=300, score_thresh=0.30, batch_size=8):\n",
    "    \"\"\"\n",
    "    Process long texts using sliding windows with entity fusion.\n",
    "    Handles documents longer than model's maximum sequence length.\n",
    "    \"\"\"\n",
    "    n = len(text)\n",
    "    step = max(1, chunk_chars - overlap)\n",
    "    windows = []\n",
    "    offsets = []\n",
    "    s = 0\n",
    "    \n",
    "    # Generate sliding windows\n",
    "    while s < n:\n",
    "        e = min(n, s + chunk_chars)\n",
    "        windows.append(text[s:e])\n",
    "        offsets.append(s)\n",
    "        s += step\n",
    "\n",
    "    # Batch processing\n",
    "    results = []\n",
    "    for i in range(0, len(windows), batch_size):\n",
    "        batch = windows[i:i+batch_size]\n",
    "        batch_off = offsets[i:i+batch_size]\n",
    "        preds_list = pipe(batch)\n",
    "        for off, preds in zip(batch_off, preds_list):\n",
    "            for p in preds:\n",
    "                if p[\"score\"] >= score_thresh:\n",
    "                    results.append({\n",
    "                        \"entity_group\": p[\"entity_group\"],\n",
    "                        \"score\": float(p[\"score\"]),\n",
    "                        \"word\": p[\"word\"],\n",
    "                        \"start\": p[\"start\"] + off,\n",
    "                        \"end\":   p[\"end\"]   + off,\n",
    "                    })\n",
    "\n",
    "    # Merge contiguous/overlapping entities\n",
    "    results.sort(key=lambda r: r[\"start\"])\n",
    "    \n",
    "    fused = []\n",
    "    for r in results:\n",
    "        if not fused:\n",
    "            fused.append(r)\n",
    "            continue\n",
    "        last = fused[-1]\n",
    "        same = (last[\"entity_group\"] == r[\"entity_group\"])\n",
    "        overlap_or_touch = (r[\"start\"] <= last[\"end\"] + 1)\n",
    "        if same and overlap_or_touch:\n",
    "            last[\"end\"] = max(last[\"end\"], r[\"end\"])\n",
    "            last[\"score\"] = max(last[\"score\"], r[\"score\"])\n",
    "            last[\"word\"] = text[last[\"start\"]:last[\"end\"]]\n",
    "        else:\n",
    "            fused.append(r)\n",
    "    \n",
    "    return fused\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f00c4838-3498-4fa5-a390-6e660bf1d192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating test set...\n",
      "\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "           CANTIDAD       1.00      1.00      1.00       974\n",
      "                EAN       1.00      1.00      1.00       851\n",
      "              FECHA       0.91      0.95      0.93        22\n",
      "    NOMBRE_PRODUCTO       0.98      0.99      0.99       988\n",
      "     NUMERO_FACTURA       0.91      0.91      0.91        22\n",
      "PRECIO_COSTE_UNIDAD       1.00      1.00      1.00       978\n",
      "                SKU       0.99      0.99      0.99       943\n",
      "\n",
      "          micro avg       0.99      1.00      0.99      4778\n",
      "          macro avg       0.97      0.98      0.97      4778\n",
      "       weighted avg       0.99      1.00      0.99      4778\n",
      "\n",
      "\n",
      "============================================================\n",
      "PERFORMANCE SUMMARY\n",
      "============================================================\n",
      "Metric               Validation           Test                \n",
      "------------------------------------------------------------\n",
      "F1                                0.9874              0.9940\n",
      "Precision                         0.9788              0.9923\n",
      "Recall                            0.9962              0.9958\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test set evaluation\n",
    "print(\"\\nEvaluating test set...\")\n",
    "test_metrics = trainer.evaluate(eval_dataset=tokenized_datasets[\"test\"])\n",
    "\n",
    "# Save test metrics\n",
    "with open(os.path.join(OUTPUT_DIR, \"test_metrics.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(test_metrics, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Performance summary table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Metric':<20} {'Validation':<20} {'Test':<20}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'F1':<20} {val_metrics.get('eval_f1', 0):>19.4f} {test_metrics.get('eval_f1', 0):>19.4f}\")\n",
    "print(f\"{'Precision':<20} {val_metrics.get('eval_precision', 0):>19.4f} {test_metrics.get('eval_precision', 0):>19.4f}\")\n",
    "print(f\"{'Recall':<20} {val_metrics.get('eval_recall', 0):>19.4f} {test_metrics.get('eval_recall', 0):>19.4f}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "\n",
    "entity_metrics = []\n",
    "for label in base_labels:\n",
    "    f1_key = f\"eval_f1_B-{label}\"\n",
    "    if f1_key in test_metrics:\n",
    "        entity_metrics.append({\n",
    "            'Entity': label,\n",
    "            'F1': test_metrics[f1_key],\n",
    "            'Precision': test_metrics.get(f\"eval_precision_B-{label}\", 0),\n",
    "            'Recall': test_metrics.get(f\"eval_recall_B-{label}\", 0),\n",
    "            'Support': int(test_metrics.get(f\"eval_support_B-{label}\", 0))\n",
    "        })\n",
    "\n",
    "if entity_metrics:\n",
    "    df = pd.DataFrame(entity_metrics).sort_values('F1', ascending=False)\n",
    "    print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bc3444d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "           CANTIDAD       1.00      1.00      1.00       974\n",
      "                EAN       1.00      1.00      1.00       851\n",
      "              FECHA       0.91      0.95      0.93        22\n",
      "    NOMBRE_PRODUCTO       0.98      0.99      0.99       988\n",
      "     NUMERO_FACTURA       0.91      0.91      0.91        22\n",
      "PRECIO_COSTE_UNIDAD       1.00      1.00      1.00       978\n",
      "                SKU       0.99      0.99      0.99       943\n",
      "\n",
      "          micro avg       0.99      1.00      0.99      4778\n",
      "          macro avg       0.97      0.98      0.97      4778\n",
      "       weighted avg       0.99      1.00      0.99      4778\n",
      "\n",
      "\n",
      "Métricas y tiempos finales guardados en final_metrics.json:\n",
      "{\n",
      "  \"train_runtime_sec\": 1325.7585,\n",
      "  \"train_runtime_min\": 22,\n",
      "  \"train_runtime_rem_sec\": 5,\n",
      "  \"train_runtime_str\": \"22m 5s\",\n",
      "  \"train_samples_per_second\": 6.653,\n",
      "  \"best_f1\": 0.9874424445374634,\n",
      "  \"val_f1\": 0.9874424445374634,\n",
      "  \"val_precision\": 0.9788381742738589,\n",
      "  \"val_recall\": 0.9961993243243243,\n",
      "  \"test_f1\": 0.9940457536822311,\n",
      "  \"test_precision\": 0.9922836287799791,\n",
      "  \"test_recall\": 0.9958141481791545,\n",
      "  \"infer_runtime_sec\": 7.9778077602386475,\n",
      "  \"infer_runtime_min\": 0,\n",
      "  \"infer_runtime_rem_sec\": 7,\n",
      "  \"infer_runtime_str\": \"0m 7s\",\n",
      "  \"avg_infer_per_sample_sec\": 0.06136775200183575,\n",
      "  \"avg_infer_per_sample_str\": \"0.061s\",\n",
      "  \"timestamp\": \"2026-02-25 21:32:45\"\n",
      "}\n",
      "\n",
      "Tiempo de entrenamiento: 22m 5s\n",
      "Tiempo de inferencia en test: 0m 7s\n",
      "Tiempo medio por factura en test: 0.061s\n"
     ]
    }
   ],
   "source": [
    "# Guardar métricas y tiempos finales en un JSON\n",
    "import time\n",
    "\n",
    "# Recoger métricas globales y tiempos\n",
    "train_runtime_sec = train_result.metrics.get(\"train_runtime\", 0)\n",
    "train_runtime_min = int(train_runtime_sec // 60)\n",
    "train_runtime_rem_sec = int(train_runtime_sec % 60)\n",
    "\n",
    "# Tiempo de inferencia en test\n",
    "num_test_samples = len(tokenized_datasets[\"test\"])\n",
    "start_infer = time.time()\n",
    "_ = trainer.predict(tokenized_datasets[\"test\"])\n",
    "end_infer = time.time()\n",
    "infer_runtime_sec = end_infer - start_infer\n",
    "infer_runtime_min = int(infer_runtime_sec // 60)\n",
    "infer_runtime_rem_sec = int(infer_runtime_sec % 60)\n",
    "avg_infer_per_sample = infer_runtime_sec / num_test_samples if num_test_samples else 0\n",
    "\n",
    "final_metrics = {\n",
    "    \"train_runtime_sec\": train_runtime_sec,\n",
    "    \"train_runtime_min\": train_runtime_min,\n",
    "    \"train_runtime_rem_sec\": train_runtime_rem_sec,\n",
    "    \"train_runtime_str\": f\"{train_runtime_min}m {train_runtime_rem_sec}s\",\n",
    "    \"train_samples_per_second\": train_result.metrics.get(\"train_samples_per_second\", 0),\n",
    "    \"best_f1\": trainer.state.best_metric,\n",
    "    \"val_f1\": val_metrics.get(\"eval_f1\", 0),\n",
    "    \"val_precision\": val_metrics.get(\"eval_precision\", 0),\n",
    "    \"val_recall\": val_metrics.get(\"eval_recall\", 0),\n",
    "    \"test_f1\": test_metrics.get(\"eval_f1\", 0),\n",
    "    \"test_precision\": test_metrics.get(\"eval_precision\", 0),\n",
    "    \"test_recall\": test_metrics.get(\"eval_recall\", 0),\n",
    "    \"infer_runtime_sec\": infer_runtime_sec,\n",
    "    \"infer_runtime_min\": infer_runtime_min,\n",
    "    \"infer_runtime_rem_sec\": infer_runtime_rem_sec,\n",
    "    \"infer_runtime_str\": f\"{infer_runtime_min}m {infer_runtime_rem_sec}s\",\n",
    "    \"avg_infer_per_sample_sec\": avg_infer_per_sample,\n",
    "    \"avg_infer_per_sample_str\": f\"{avg_infer_per_sample:.3f}s\",\n",
    "    \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "}\n",
    "\n",
    "# Guardar en archivo\n",
    "with open(os.path.join(OUTPUT_DIR, \"final_metrics.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_metrics, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\nMétricas y tiempos finales guardados en final_metrics.json:\")\n",
    "print(json.dumps(final_metrics, indent=2, ensure_ascii=False))\n",
    "print(f\"\\nTiempo de entrenamiento: {final_metrics['train_runtime_str']}\")\n",
    "print(f\"Tiempo de inferencia en test: {final_metrics['infer_runtime_str']}\")\n",
    "print(f\"Tiempo medio por factura en test: {final_metrics['avg_infer_per_sample_str']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM CUDA NER",
   "language": "python",
   "name": "tfm_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
